{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CICIDS 2018 Full Dataset - Advanced IDS Training\n",
    "## High-Accuracy Deep Learning Model for Intrusion Detection\n",
    "\n",
    "This notebook trains a state-of-the-art intrusion detection model using the complete CICIDS 2018 dataset.\n",
    "\n",
    "**Features:**\n",
    "- Full CICIDS 2018 dataset (~16M samples)\n",
    "- Advanced CNN + Attention architecture\n",
    "- Comprehensive preprocessing and feature engineering\n",
    "- Hyperparameter optimization\n",
    "- Detailed evaluation metrics\n",
    "- Model export for deployment\n",
    "\n",
    "**Estimated Runtime:** 6-10 hours on Google Colab GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages - using compatible versions\n!pip install -q tensorflow\n!pip install -q scikit-learn\n!pip install -q pandas numpy matplotlib seaborn\n!pip install -q imbalanced-learn\n!pip install -q boto3\n!pip install -q tqdm\n\nprint(\"‚úì All packages installed successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import libraries\nimport os\nimport sys\nimport json\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, callbacks, optimizers\nfrom tensorflow.keras.layers import (\n    Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D,\n    GlobalAveragePooling1D, LayerNormalization, Input,\n    Concatenate, Reshape\n)\n\n# Try to import MultiHeadAttention, but don't fail if not available\ntry:\n    from tensorflow.keras.layers import MultiHeadAttention\n    ATTENTION_AVAILABLE = True\nexcept ImportError:\n    ATTENTION_AVAILABLE = False\n    print(\"MultiHeadAttention not available in this TensorFlow version\")\n\n# Scikit-learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, roc_auc_score,\n    roc_curve, precision_recall_curve, f1_score, accuracy_score\n)\n\n# Imbalanced-learn\ntry:\n    from imblearn.over_sampling import SMOTE\n    SMOTE_AVAILABLE = True\nexcept ImportError:\n    SMOTE_AVAILABLE = False\n    print(\"SMOTE not available - install imbalanced-learn if needed\")\n\n# AWS S3 for dataset download\nimport boto3\nfrom botocore import UNSIGNED\nfrom botocore.config import Config as BotoConfig\n\n# Check GPU availability\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\nif tf.config.list_physical_devices('GPU'):\n    print(\"‚úì GPU is available for training!\")\nelse:\n    print(\"‚ö† No GPU found. Training will be slower on CPU.\")\n    print(\"Tip: In Colab, go to Runtime > Change runtime type > Hardware accelerator > GPU\")\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(\"\\n‚úì All libraries imported successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download CICIDS 2018 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "S3_BUCKET = 'cse-cic-ids2018'\n",
    "S3_REGION = 'ca-central-1'\n",
    "S3_PREFIX = 'Processed Traffic Data for ML Algorithms/'\n",
    "DATA_DIR = Path('/content/cicids2018_data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Expected files in CICIDS 2018 dataset\n",
    "EXPECTED_FILES = [\n",
    "    'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv',\n",
    "    'Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "    'Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "    'Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "    'Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "    'Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "    'Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "    'Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv',\n",
    "]\n",
    "\n",
    "def download_from_s3(filename, local_path):\n",
    "    \"\"\"Download a file from S3\"\"\"\n",
    "    try:\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            region_name=S3_REGION,\n",
    "            config=BotoConfig(signature_version=UNSIGNED)\n",
    "        )\n",
    "        \n",
    "        s3_key = S3_PREFIX + filename\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        s3_client.download_file(S3_BUCKET, s3_key, str(local_path))\n",
    "        print(f\"‚úì Downloaded {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error downloading {filename}: {e}\")\n",
    "        return False\n",
    "\n",
    "# List available files in S3\n",
    "print(\"Discovering files in S3 bucket...\")\n",
    "try:\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        region_name=S3_REGION,\n",
    "        config=BotoConfig(signature_version=UNSIGNED)\n",
    "    )\n",
    "    \n",
    "    available_files = []\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=S3_BUCKET, Prefix=S3_PREFIX)\n",
    "    \n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                key = obj['Key']\n",
    "                if key.endswith('.csv') and 'TrafficForML' in key:\n",
    "                    filename = os.path.basename(key)\n",
    "                    size_mb = obj['Size'] / (1024 * 1024)\n",
    "                    available_files.append((filename, size_mb))\n",
    "    \n",
    "    print(f\"\\nFound {len(available_files)} CSV files:\")\n",
    "    total_size = 0\n",
    "    for filename, size in available_files:\n",
    "        print(f\"  - {filename} ({size:.2f} MB)\")\n",
    "        total_size += size\n",
    "    print(f\"\\nTotal dataset size: {total_size:.2f} MB (~{total_size/1024:.2f} GB)\")\n",
    "    \n",
    "    # Update expected files\n",
    "    if available_files:\n",
    "        EXPECTED_FILES = [f[0] for f in available_files]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not list S3 files: {e}\")\n",
    "    print(\"Using default file list...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Ready to download dataset\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all CSV files\n",
    "print(\"Starting download of CICIDS 2018 dataset...\")\n",
    "print(\"This may take 30-60 minutes depending on connection speed.\\n\")\n",
    "\n",
    "downloaded_files = []\n",
    "for filename in EXPECTED_FILES:\n",
    "    local_path = DATA_DIR / filename\n",
    "    \n",
    "    # Skip if already downloaded\n",
    "    if local_path.exists():\n",
    "        print(f\"‚úì {filename} already exists, skipping...\")\n",
    "        downloaded_files.append(str(local_path))\n",
    "        continue\n",
    "    \n",
    "    # Download file\n",
    "    if download_from_s3(filename, local_path):\n",
    "        downloaded_files.append(str(local_path))\n",
    "\n",
    "print(f\"\\n‚úì Downloaded {len(downloaded_files)}/{len(EXPECTED_FILES)} files successfully!\")\n",
    "print(f\"Files saved to: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the first file\n",
    "if downloaded_files:\n",
    "    sample_file = downloaded_files[0]\n",
    "    print(f\"Loading sample from: {sample_file}\\n\")\n",
    "    \n",
    "    # Read first few rows\n",
    "    df_sample = pd.read_csv(sample_file, nrows=1000, low_memory=False)\n",
    "    \n",
    "    print(f\"Dataset shape: {df_sample.shape}\")\n",
    "    print(f\"\\nColumn names ({len(df_sample.columns)} features):\")\n",
    "    for i, col in enumerate(df_sample.columns, 1):\n",
    "        print(f\"{i:3d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nLabel distribution in sample:\")\n",
    "    print(df_sample['Label'].value_counts())\n",
    "    \n",
    "    print(f\"\\nData types:\")\n",
    "    print(df_sample.dtypes.value_counts())\n",
    "    \n",
    "    print(f\"\\nMemory usage:\")\n",
    "    print(f\"{df_sample.memory_usage(deep=True).sum() / 1024**2:.2f} MB for 1000 samples\")\n",
    "else:\n",
    "    print(\"‚ö† No files downloaded. Please run the download cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CICIDS2018Preprocessor:\n",
    "    \"\"\"Advanced preprocessing pipeline for CICIDS 2018 dataset\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_names = None\n",
    "        self.protocol_map = {'TCP': 1, 'UDP': 2, 'ICMP': 3}\n",
    "        \n",
    "    def load_and_preprocess_file(self, filepath, sample_frac=None):\n",
    "        \"\"\"\n",
    "        Load and preprocess a single CSV file\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to CSV file\n",
    "            sample_frac: Fraction of data to sample (None = use all)\n",
    "        \"\"\"\n",
    "        print(f\"\\nProcessing: {os.path.basename(filepath)}\")\n",
    "        \n",
    "        # Load data in chunks to handle memory efficiently\n",
    "        chunks = []\n",
    "        chunk_size = 100000\n",
    "        \n",
    "        for chunk in pd.read_csv(filepath, chunksize=chunk_size, low_memory=False):\n",
    "            # Clean column names\n",
    "            chunk.columns = chunk.columns.str.strip()\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "        print(f\"  Loaded {len(df):,} samples\")\n",
    "        \n",
    "        # Sample if requested\n",
    "        if sample_frac and sample_frac < 1.0:\n",
    "            df = df.sample(frac=sample_frac, random_state=42)\n",
    "            print(f\"  Sampled to {len(df):,} samples ({sample_frac*100}%)\")\n",
    "        \n",
    "        # Clean data\n",
    "        df = self._clean_data(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_data(self, df):\n",
    "        \"\"\"Clean and prepare data\"\"\"\n",
    "        # Remove duplicate rows\n",
    "        initial_size = len(df)\n",
    "        df = df.drop_duplicates()\n",
    "        if len(df) < initial_size:\n",
    "            print(f\"  Removed {initial_size - len(df):,} duplicate rows\")\n",
    "        \n",
    "        # Handle missing values\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Fill numeric columns with median\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "        \n",
    "        # Map protocol if exists\n",
    "        if 'Protocol' in df.columns:\n",
    "            df['Protocol'] = df['Protocol'].map(\n",
    "                lambda x: self.protocol_map.get(str(x).upper(), 0)\n",
    "            )\n",
    "        \n",
    "        # Create binary label: benign (0) vs malicious (1)\n",
    "        if 'Label' in df.columns:\n",
    "            df['Label'] = df['Label'].apply(\n",
    "                lambda x: 0 if 'Benign' in str(x) else 1\n",
    "            )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        Prepare features for training\n",
    "        \n",
    "        Returns:\n",
    "            X: Feature array\n",
    "            y: Label array\n",
    "        \"\"\"\n",
    "        # Separate features and labels\n",
    "        if 'Label' not in df.columns:\n",
    "            raise ValueError(\"Label column not found\")\n",
    "        \n",
    "        y = df['Label'].values\n",
    "        \n",
    "        # Drop non-feature columns\n",
    "        feature_df = df.drop(columns=['Label'], errors='ignore')\n",
    "        \n",
    "        # Drop timestamp columns if present\n",
    "        timestamp_cols = [col for col in feature_df.columns if 'Timestamp' in col]\n",
    "        feature_df = feature_df.drop(columns=timestamp_cols, errors='ignore')\n",
    "        \n",
    "        # Store feature names\n",
    "        self.feature_names = feature_df.columns.tolist()\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        X = feature_df.values\n",
    "        \n",
    "        print(f\"  Features: {X.shape[1]}\")\n",
    "        print(f\"  Samples: {X.shape[0]:,}\")\n",
    "        print(f\"  Benign: {np.sum(y == 0):,} ({np.sum(y == 0) / len(y) * 100:.2f}%)\")\n",
    "        print(f\"  Malicious: {np.sum(y == 1):,} ({np.sum(y == 1) / len(y) * 100:.2f}%)\")\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def scale_features(self, X_train, X_val=None, X_test=None):\n",
    "        \"\"\"\n",
    "        Scale features using StandardScaler\n",
    "        \"\"\"\n",
    "        print(\"\\nScaling features...\")\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        results = {'train': X_train_scaled}\n",
    "        \n",
    "        if X_val is not None:\n",
    "            results['val'] = self.scaler.transform(X_val)\n",
    "        \n",
    "        if X_test is not None:\n",
    "            results['test'] = self.scaler.transform(X_test)\n",
    "        \n",
    "        print(\"‚úì Features scaled\")\n",
    "        return results\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = CICIDS2018Preprocessor()\n",
    "print(\"‚úì Preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process all downloaded files\nprint(\"=\"*60)\nprint(\"Processing CICIDS 2018 Dataset - 10% SAMPLE MODE\")\nprint(\"=\"*60)\nprint(\"\\nThis will process 10% of each file for faster training.\")\nprint(\"Estimated time: 15-20 minutes\\n\")\n\n# SAMPLE MODE ENABLED - Use 10% of data for faster training\nUSE_SAMPLE = True  # ‚úì ENABLED - Change to False for full dataset\nSAMPLE_FRAC = 0.1  # Using 10% of each file (~1.2-1.6M samples)\n\nprint(f\"üöÄ SAMPLE MODE: Using {SAMPLE_FRAC*100}% of data\")\nprint(f\"   Expected: ~1.2-1.6M samples\")\nprint(f\"   Training time: ~30-45 minutes\\n\")\nprint(\"üí° To use full dataset, set USE_SAMPLE = False\\n\")\n\nall_data = []\nfor filepath in downloaded_files:\n    try:\n        df = preprocessor.load_and_preprocess_file(\n            filepath, \n            sample_frac=SAMPLE_FRAC if USE_SAMPLE else None\n        )\n        all_data.append(df)\n    except Exception as e:\n        print(f\"  ‚úó Error processing {filepath}: {e}\")\n\n# Combine all data\nprint(\"\\nCombining all files...\")\ncombined_df = pd.concat(all_data, ignore_index=True)\nprint(f\"‚úì Total dataset size: {len(combined_df):,} samples\")\n\n# Shuffle data\nprint(\"\\nShuffling dataset...\")\ncombined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\nprint(\"‚úì Dataset shuffled\")\n\n# Display class distribution\nprint(\"\\nFinal Class Distribution:\")\nlabel_counts = combined_df['Label'].value_counts()\nprint(f\"  Benign (0): {label_counts.get(0, 0):,}\")\nprint(f\"  Malicious (1): {label_counts.get(1, 0):,}\")\n\n# Prepare features\nprint(\"\\nPreparing features...\")\nX, y = preprocessor.prepare_features(combined_df)\n\n# Free up memory\ndel combined_df, all_data\nimport gc\ngc.collect()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Data Preprocessing Complete\")\nprint(\"=\"*60)\nprint(f\"Feature matrix shape: {X.shape}\")\nprint(f\"Label vector shape: {y.shape}\")\nprint(f\"\\n‚úì Ready for training with {len(X):,} samples!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 70% train, 15% validation, 15% test\n",
    "print(\"Splitting dataset...\\n\")\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 50% of temp = 15% val, 15% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Split sizes:\")\n",
    "print(f\"  Training:   {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(X_val):,} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test:       {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"  Train - Benign: {np.sum(y_train==0):,}, Malicious: {np.sum(y_train==1):,}\")\n",
    "print(f\"  Val   - Benign: {np.sum(y_val==0):,}, Malicious: {np.sum(y_val==1):,}\")\n",
    "print(f\"  Test  - Benign: {np.sum(y_test==0):,}, Malicious: {np.sum(y_test==1):,}\")\n",
    "\n",
    "# Free up memory\n",
    "del X, y, X_temp, y_temp\n",
    "gc.collect()\n",
    "\n",
    "# Scale features\n",
    "scaled = preprocessor.scale_features(X_train, X_val, X_test)\n",
    "X_train_scaled = scaled['train']\n",
    "X_val_scaled = scaled['val']\n",
    "X_test_scaled = scaled['test']\n",
    "\n",
    "print(\"\\n‚úì Data ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Model Architecture\n",
    "\n",
    "We'll implement a hybrid CNN + Attention architecture optimized for IDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_advanced_ids_model(input_dim, model_type='cnn_attention'):\n    \"\"\"\n    Create advanced IDS model\n    \n    Args:\n        input_dim: Number of input features\n        model_type: 'cnn_attention', 'deep_cnn', or 'dense'\n    \"\"\"\n    inputs = Input(shape=(input_dim,))\n    \n    if model_type == 'cnn_attention':\n        # Reshape for CNN\n        x = Reshape((input_dim, 1))(inputs)\n        \n        # CNN blocks\n        x = Conv1D(128, 3, activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling1D(2)(x)\n        x = Dropout(0.3)(x)\n        \n        x = Conv1D(256, 3, activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        x = MaxPooling1D(2)(x)\n        x = Dropout(0.3)(x)\n        \n        x = Conv1D(512, 3, activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.3)(x)\n        \n        # Try to use MultiHeadAttention if available, otherwise skip\n        try:\n            attention_output = MultiHeadAttention(\n                num_heads=8, key_dim=64, dropout=0.2\n            )(x, x)\n            x = LayerNormalization()(attention_output + x)\n        except:\n            # Fallback: just use the CNN output\n            print(\"MultiHeadAttention not available, using CNN only\")\n        \n        # Global pooling\n        x = GlobalAveragePooling1D()(x)\n        \n        # Dense layers\n        x = Dense(512, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        \n        x = Dense(256, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.4)(x)\n        \n    elif model_type == 'deep_cnn':\n        # Deep CNN architecture\n        x = Reshape((input_dim, 1))(inputs)\n        \n        # Multiple CNN blocks\n        for filters in [64, 128, 256, 512]:\n            x = Conv1D(filters, 3, activation='relu', padding='same')(x)\n            x = BatchNormalization()(x)\n            x = Conv1D(filters, 3, activation='relu', padding='same')(x)\n            x = BatchNormalization()(x)\n            x = MaxPooling1D(2)(x)\n            x = Dropout(0.3)(x)\n        \n        x = GlobalAveragePooling1D()(x)\n        \n        x = Dense(512, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(0.5)(x)\n        \n        x = Dense(256, activation='relu')(x)\n        x = Dropout(0.4)(x)\n        \n    else:  # dense\n        # Deep dense network\n        x = inputs\n        \n        for units in [1024, 512, 256, 128]:\n            x = Dense(units, activation='relu')(x)\n            x = BatchNormalization()(x)\n            x = Dropout(0.4)(x)\n    \n    # Output layer\n    outputs = Dense(1, activation='sigmoid')(x)\n    \n    model = models.Model(inputs=inputs, outputs=outputs)\n    \n    return model\n\n# Create model\nprint(\"Creating advanced IDS model...\\n\")\n\n# Choose model type - use 'deep_cnn' for better compatibility\nMODEL_TYPE = 'deep_cnn'  # Options: 'cnn_attention', 'deep_cnn', 'dense'\nprint(f\"Using model type: {MODEL_TYPE}\")\n\nmodel = create_advanced_ids_model(\n    input_dim=X_train_scaled.shape[1],\n    model_type=MODEL_TYPE\n)\n\n# Compile model\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=0.001),\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall'),\n        tf.keras.metrics.AUC(name='auc')\n    ]\n)\n\n# Display model summary\nmodel.summary()\n\n# Count parameters\ntotal_params = model.count_params()\nprint(f\"\\nTotal parameters: {total_params:,}\")\nprint(f\"Model type: {MODEL_TYPE}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Configuration and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training callbacks\n",
    "checkpoint_dir = Path('/content/checkpoints')\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "callbacks_list = [\n",
    "    # Save best model\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=str(checkpoint_dir / 'best_model.h5'),\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        patience=15,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=str(checkpoint_dir / 'logs'),\n",
    "        histogram_freq=1\n",
    "    ),\n",
    "    \n",
    "    # CSV logger\n",
    "    callbacks.CSVLogger(\n",
    "        str(checkpoint_dir / 'training_log.csv'),\n",
    "        append=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úì Callbacks configured\")\n",
    "print(\"\\nCallbacks:\")\n",
    "print(\"  - ModelCheckpoint: Save best model based on validation AUC\")\n",
    "print(\"  - EarlyStopping: Stop if no improvement for 15 epochs\")\n",
    "print(\"  - ReduceLROnPlateau: Reduce learning rate when stuck\")\n",
    "print(\"  - TensorBoard: Log metrics for visualization\")\n",
    "print(\"  - CSVLogger: Save training history to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training configuration - Optimized for 10% sample mode\nBATCH_SIZE = 256\nEPOCHS = 50  # Reduced for faster training with sample data\n\nprint(\"=\"*60)\nprint(\"Starting Model Training - 10% SAMPLE MODE\")\nprint(\"=\"*60)\nprint(f\"Model: {MODEL_TYPE}\")\nprint(f\"Batch size: {BATCH_SIZE}\")\nprint(f\"Max epochs: {EPOCHS}\")\nprint(f\"Training samples: {len(X_train_scaled):,}\")\nprint(f\"Validation samples: {len(X_val_scaled):,}\")\nprint(\"\\n‚è±Ô∏è Estimated training time: 25-35 minutes\")\nprint(\"Training will stop early if validation AUC stops improving.\\n\")\n\n# Start training\nstart_time = datetime.now()\nprint(f\"üöÄ Training started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n\nhistory = model.fit(\n    X_train_scaled, y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=(X_val_scaled, y_val),\n    callbacks=callbacks_list,\n    verbose=1\n)\n\nend_time = datetime.now()\ntraining_duration = end_time - start_time\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Training Complete!\")\nprint(\"=\"*60)\nprint(f\"‚è±Ô∏è Training duration: {training_duration}\")\nprint(f\"‚úì Completed at: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"üìä Actual epochs trained: {len(history.history['loss'])}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Model Accuracy')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Model Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train')\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation')\n",
    "axes[1, 0].set_title('Model Precision')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train')\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation')\n",
    "axes[1, 1].set_title('Model Recall')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(checkpoint_dir / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Training history plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = checkpoint_dir / 'best_model.h5'\n",
    "if best_model_path.exists():\n",
    "    print(\"Loading best model...\")\n",
    "    model = keras.models.load_model(str(best_model_path))\n",
    "    print(\"‚úì Best model loaded\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_results = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Test Set Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Loss:      {test_results[0]:.6f}\")\n",
    "print(f\"Accuracy:  {test_results[1]:.4f} ({test_results[1]*100:.2f}%)\")\n",
    "print(f\"Precision: {test_results[2]:.4f} ({test_results[2]*100:.2f}%)\")\n",
    "print(f\"Recall:    {test_results[3]:.4f} ({test_results[3]*100:.2f}%)\")\n",
    "print(f\"AUC:       {test_results[4]:.4f}\")\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "y_pred_proba = model.predict(X_test_scaled, batch_size=BATCH_SIZE, verbose=1)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Additional metrics\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(\n",
    "    y_test, y_pred,\n",
    "    target_names=['Benign', 'Malicious'],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=['Benign', 'Malicious'],\n",
    "    yticklabels=['Benign', 'Malicious']\n",
    ")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(checkpoint_dir / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics from confusion matrix\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nConfusion Matrix Breakdown:\")\n",
    "print(f\"  True Negatives:  {tn:,}\")\n",
    "print(f\"  False Positives: {fp:,}\")\n",
    "print(f\"  False Negatives: {fn:,}\")\n",
    "print(f\"  True Positives:  {tp:,}\")\n",
    "\n",
    "# False positive and false negative rates\n",
    "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "print(f\"\\nFalse Positive Rate: {fpr:.4f} ({fpr*100:.2f}%)\")\n",
    "print(f\"False Negative Rate: {fnr:.4f} ({fnr*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_roc, tpr_roc, color='darkorange', lw=2,\n",
    "         label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(checkpoint_dir / 'roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve, precision_curve, color='blue', lw=2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(checkpoint_dir / 'precision_recall_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì All evaluation plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "output_dir = Path('/content/output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Saving model and artifacts...\\n\")\n",
    "\n",
    "# Save model in different formats\n",
    "model.save(str(output_dir / 'cicids2018_ids_model.h5'))\n",
    "print(\"‚úì Saved model in H5 format\")\n",
    "\n",
    "model.save(str(output_dir / 'cicids2018_ids_model_savedmodel'))\n",
    "print(\"‚úì Saved model in SavedModel format\")\n",
    "\n",
    "# Save preprocessor\n",
    "with open(output_dir / 'preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "print(\"‚úì Saved preprocessor\")\n",
    "\n",
    "# Save training history\n",
    "with open(output_dir / 'training_history.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'history': {k: [float(v) for v in vals] for k, vals in history.history.items()},\n",
    "        'training_duration': str(training_duration),\n",
    "        'model_type': MODEL_TYPE,\n",
    "        'total_params': int(total_params),\n",
    "    }, f, indent=2)\n",
    "print(\"‚úì Saved training history\")\n",
    "\n",
    "# Save evaluation results\n",
    "eval_results = {\n",
    "    'test_metrics': {\n",
    "        'accuracy': float(test_results[1]),\n",
    "        'precision': float(test_results[2]),\n",
    "        'recall': float(test_results[3]),\n",
    "        'auc': float(test_results[4]),\n",
    "        'f1_score': float(f1),\n",
    "        'false_positive_rate': float(fpr),\n",
    "        'false_negative_rate': float(fnr)\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'test_samples': int(len(y_test)),\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'training_date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(output_dir / 'evaluation_results.json', 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "print(\"‚úì Saved evaluation results\")\n",
    "\n",
    "# Save feature names\n",
    "with open(output_dir / 'feature_names.json', 'w') as f:\n",
    "    json.dump({'features': preprocessor.feature_names}, f, indent=2)\n",
    "print(\"‚úì Saved feature names\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All artifacts saved to:\", output_dir)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# List saved files\n",
    "print(\"\\nSaved files:\")\n",
    "for file in sorted(output_dir.iterdir()):\n",
    "    size_mb = file.stat().st_size / (1024 * 1024) if file.is_file() else 0\n",
    "    print(f\"  - {file.name} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Download Results to Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file of all outputs for easy download\n",
    "import shutil\n",
    "\n",
    "print(\"Creating archive for download...\\n\")\n",
    "\n",
    "archive_path = '/content/cicids2018_ids_model'\n",
    "shutil.make_archive(archive_path, 'zip', output_dir)\n",
    "\n",
    "archive_file = archive_path + '.zip'\n",
    "archive_size = Path(archive_file).stat().st_size / (1024 * 1024)\n",
    "\n",
    "print(f\"‚úì Archive created: {archive_file}\")\n",
    "print(f\"  Size: {archive_size:.2f} MB\")\n",
    "print(\"\\nDownload this file to use the trained model in your IDS system.\")\n",
    "\n",
    "# In Colab, you can download using:\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"\\nInitiating download...\")\n",
    "    files.download(archive_file)\n",
    "except ImportError:\n",
    "    print(\"\\nNot running in Colab. Archive saved at:\", archive_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(X_train_scaled) + len(X_val_scaled) + len(X_test_scaled):,}\")\n",
    "print(f\"  Training samples: {len(X_train_scaled):,}\")\n",
    "print(f\"  Validation samples: {len(X_val_scaled):,}\")\n",
    "print(f\"  Test samples: {len(X_test_scaled):,}\")\n",
    "print(f\"  Features: {X_train_scaled.shape[1]}\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è Model Architecture:\")\n",
    "print(f\"  Type: {MODEL_TYPE}\")\n",
    "print(f\"  Parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è Training Time:\")\n",
    "print(f\"  Duration: {training_duration}\")\n",
    "print(f\"  Epochs completed: {len(history.history['loss'])}\")\n",
    "\n",
    "print(\"\\nüéØ Performance Metrics:\")\n",
    "print(f\"  Accuracy:  {test_results[1]*100:.2f}%\")\n",
    "print(f\"  Precision: {test_results[2]*100:.2f}%\")\n",
    "print(f\"  Recall:    {test_results[3]*100:.2f}%\")\n",
    "print(f\"  F1-Score:  {f1*100:.2f}%\")\n",
    "print(f\"  AUC-ROC:   {test_results[4]:.4f}\")\n",
    "\n",
    "print(\"\\nüö® Error Analysis:\")\n",
    "print(f\"  False Positive Rate: {fpr*100:.2f}%\")\n",
    "print(f\"  False Negative Rate: {fnr*100:.2f}%\")\n",
    "\n",
    "# Success criteria check\n",
    "print(\"\\n‚úÖ Success Criteria:\")\n",
    "criteria = [\n",
    "    (\"Accuracy >= 95%\", test_results[1] >= 0.95),\n",
    "    (\"Precision >= 90%\", test_results[2] >= 0.90),\n",
    "    (\"Recall >= 90%\", test_results[3] >= 0.90),\n",
    "    (\"F1-Score >= 90%\", f1 >= 0.90),\n",
    "    (\"AUC >= 0.95\", test_results[4] >= 0.95),\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for criterion, passed in criteria:\n",
    "    status = \"‚úì\" if passed else \"‚úó\"\n",
    "    print(f\"  {status} {criterion}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\nüéâ All success criteria met!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some criteria not met. Consider:\")\n",
    "    print(\"  - Training for more epochs\")\n",
    "    print(\"  - Adjusting hyperparameters\")\n",
    "    print(\"  - Trying different model architectures\")\n",
    "    print(\"  - Applying more advanced data augmentation\")\n",
    "\n",
    "print(\"\\nüì¶ Output Files:\")\n",
    "print(f\"  Location: {output_dir}\")\n",
    "print(\"  Files:\")\n",
    "print(\"    - cicids2018_ids_model.h5 (Keras model)\")\n",
    "print(\"    - preprocessor.pkl (Feature scaler)\")\n",
    "print(\"    - evaluation_results.json (Metrics)\")\n",
    "print(\"    - training_history.json (Training logs)\")\n",
    "print(\"    - feature_names.json (Feature list)\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  1. Download the model archive\")\n",
    "print(\"  2. Integrate into your IDS backend\")\n",
    "print(\"  3. Test with live traffic data\")\n",
    "print(\"  4. Monitor performance in production\")\n",
    "print(\"  5. Retrain periodically with new attack data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}